{
    "cancel": "Cancel",
    "save": "Save",
    "byeMenu": "Bye, Menu!",
    "helloPlugin": "Hello, Plugin!",
    "byePlugin": "Bye, Plugin!",
    "summarize": "Summarize",
    "autoTag": "Auto Tag Doc",
    "saveChat": "Save Chat",
    "clear": "Clear",
    "chatPlaceHolder": "How can I help you today?\nTry @ for more action.",
    "send": "Send",
    "saveChatTitle": "Save chat history to Notebook",
    "saveChatDesc": "Select the notebook to save the chat history.",
    "role": "Role",
    "roleDesc": "Set a default role for your LLM.",
    "aiEmoji": "Emoji / Text",
    "aiEmojiDesc": "Emoji / Text that is auto inject in front of the AI generated content when user copy from the chat. Best way to get an emoji now is to copy from your markdown document now and paste it here. This setting is recommened as there is a risk in using AI, one of it will be disinformation and over / under reliance of AI.",
    "enterToSend": "Press Enter to send",
    "enterToSendDesc": "Press Enter button to send message when typing in chat box.",
    "customSystemPrompt": "Custom system prompt",
    "customSystemPromptDesc": "Customize your system prompt to instruct how LLM should work. Using this will override the role setting.",
    "customUserPrompt": "Custom user prompt",
    "customUserPromptDesc": "Customize your user prompt. This will be adding to the beginning of your prompt when you are interact with the LLM.",
    "settings": "Notebook Assistant settings",
    "pluginName": "Notebook Assistant",
    "pleaseSelect": "Please select",
    "PA": "Personal Assistant",
    "CD": "Programmer",
    "SE": "Software Engineer",
    "SA": "Solution Architect",
    "ET": "English Teacher",
    "TG": "Travel Guide",
    "PC": "Plagiarism Checker",
    "ST": "Storyteller",
    "MT": "Math Teacher",
    "CS": "Cyber Security Specialist",
    "FA": "Financial Analyst",
    "ML": "Machine Learning Engineer",
    "DS": "Data Scientist",
    "noAIDetected": "You need to configure the AI setting before using this plugin.",
    "noAIDetected2": "Under Setting > AI",
    "noNotebookSelected": "No notebook is selected to save chat history, select it via pluggin setting.",
    "AIConfigTitle": "NOTE",
    "AIConfigDesc": "Please note that this plugin leverage on SiYuan default AI setting, you will be to configure the AI setting before you start using Notebook Assistant.",
    "localEmbeddingEnabled": "Enable Local Embedding Service",
    "localEmbeddingEnabledDesc": "Enable Local Embedding Service will be using transformer.js and onnx runtime within SiYuan to create embedding. There may be a slightly slow during the process. This feature is required for RAG (Retrieval-Augmented Generation) using your own data. All the data is stored within SiYuan.",
    "tagsAdded": "Tags is added to document",
    "noTagsSelected": "No tags is selected",
    "summarySaved": "Summary is saved",
    "selectTags": "Select the tags below to add into your document",
    "summaryText": "AI Summary",
    "noResult": "No result",
    "searchNote": "Similarity search is a search method that retrieves objects based on their similarity to a query object, rather than exact keyword matching. You are going to have different experience compare to full text search and no guarantee the result return is relevant.",
    "blockNotFound": "Block not found, it may be deleted or removed",
    "searchNotebook": "Search Notebook",
    "allNotebook": "All Notebooks",
    "createdEmbeddings": "has created an embeddings copy",
    "resultFound": "Result found",
    "similarity": "Similarity",
    "fts": "full text search",
    "ss": "similarity search",
    "getContentFromNotebook": "Getting content from notebook",
    "downloadOnnxRuntime": "Downloading model from huggingface and setup onyxruntime",
    "embddingModelCreated": "Embedding model is setup",
    "createdEmbeddingsSuccess": "Successfully created embeddings",
    "unableToSetupVDB": "Unable to setup local embedding model",
    "embeddedAndChunk": "Creating embeddings and chunking for notebook",
    "selectNotebook": "Select Notebook",
    "createEmbeddingsNote1": "This action will be create embedding based on your notebook and documents, it will take approximately 1 - 60 minutes, depending on your machine performance and the data you have. While running this action, DO NOT close nb-assistant or exit SiYuan. After this process is done, you will be able to use the embedding created by this notebook for RAG.",
    "createEmbeddingsNote2": "Embeddings created is not auto updated as it is an heavy task that may affect SiYuan's performance. Therefore, it will required user effort to select the notebook to create embedding and chunking. Select the same notebook will drop the existing copies and re-create with latest notebook contents.",
    "createEmbeddingsNote3": "Creating embeddings for all notebooks will take longer time, depending on your machine performance and notebook contents. Please be patient while waiting.",
    "confirm": "Confirm",
    "searchContent": "search from your document",
    "nothingToEmbed": "Nothing is transform, double check if the notebook is empty. If not, please open a ticket to developer on github",
    "processTakeX": "This process may take approximately",
    "minutes": "minutes",
    "saveVDBFail": "save vector db failed, retry in 5 seconds",
    "remainingXToProcess": "Remaining [x] to process",
    "processedXAndYLeft": "Processed [x] chunks, remaining [y] to process",
    "usePromptChaining": "Use Prompt Chaining",
    "usePromptChainingDesc": "To improve the reliability and performance of LLMs, prompt chaining is one of the techniques. It break tasks into its subtasks and uses its output as input for the subsequent chain. This is useful for complex tasks but it also consume MORE tokens, therefore, be aware of using such option. ",
    "cacheModel": "Embedding Service",
    "cacheModelDesc": "Local Embedding Service will be using transformer.js and onnx runtime within SiYuan to create embedding. There may be a slightly slow during the process. This feature is required for RAG (Retrieval-Augmented Generation) using your own data. All the data is stored within SiYuan.",
    "cacheModelDesc2": "The downloaded model will be cached in SiYuan, however, caches may be missing / reset after you exit SiYuan. You can toggle this option to cache it again.",
    "saveToDoc": "Save to document",
    "embeddingAlert": "Please ensure you are not choosing the notebook with any sensitive information. While RAG retrieval process, it may be retrieved and being send to the AI service.",
    "embeddingHint": "After embedding is created, you can use '@' to select the notebook and supply the notebook's content for RAG process.",
    "aiApiKey": "API key required to access the AI service.",
    "aiApiUrl": "Base URL endpoint for the AI service API. Examples: 'https://api.openai.com' for OpenAI, 'https://api.anthropic.com' for Claude, or 'http://localhost:11434' for local Ollama.",
    "aiModel": "Specific AI model identifier to use. Examples: 'gpt-4' for OpenAI, 'claude-3-opus-20240229' for Anthropic, or 'llama2' for Ollama. Different models have varying capabilities and costs.",
    "aiCustomSystemPrompt": "Initial system-level instructions that set the AI's behavior, role, and constraints. This prompt is provided once at the start of the conversation to establish context and guidelines. This will be applied on top of every messages when you using this model.",
    "aiCustomUserPrompt": "Template or prefix for user messages. Can be used to format or provide additional context to each user input before it's sent to the AI. This will be applied on top of every messages when you using this model.",
    "aiMaxTokens": "Maximum number of tokens (words/characters) the AI should generate in its response. Higher values allow longer responses but consume more resources. Typical range: 256-4096.",
    "aiTemperature": "Controls randomness in the AI's responses. Range 0.0-2.0. Lower values (e.g., 0.2) give focused, deterministic responses; higher values (e.g., 0.8) produce more creative, varied outputs.",
    "aiTopP": "Nucleus sampling parameter. Range 0.0-1.0. Controls diversity by selecting from the smallest set of tokens whose cumulative probability exceeds this value. Lower values make output more focused.",
    "aiTopK": "Limits token selection to the K most likely next tokens. Lower values (e.g., 40) make output more focused, while higher values allow more diverse possibilities.",
    "aiPresencePenalty": "Range -2.0 to 2.0. Adjusts likelihood of discussing new topics. Positive values encourage the model to talk about new topics, while negative values make it focus on existing topics.",
    "aiFrequencyPenalty": "Range -2.0 to 2.0. Adjusts likelihood of token repetition. Positive values reduce repetition by penalizing frequently used tokens, while negative values allow more repetition.",
    "aiStopWords": "Array of strings that signal the AI to stop generating further content. Useful for controlling response format and preventing unwanted continuations. Example: ###,Human,Assistant",
    "aiChooseEmbedding": "Local models run directly on your machine, providing privacy and no internet dependency. However, it may not provide as good quality as online AI service.",
    "aiEmbeddingModelDesc": "Embedding model used to create embedding for RAG process and similarity search.",
    "aiLocalEmbedding": "Local Model (Transformer.js)",
    "aiAiproviderEmbedding": "AI Provider",
    "aiEmbeddingModel": "Embedding Model",
    "aiEmbeddingModelProvider": "Embedding Model Provider",
    "aiTitleApiKey": "API Key",
    "aiTitleApiUrl": "API URL",
    "aiTitleModel": "Model",
    "aiTitleCustomSystemPrompt": "Custom System Prompt",
    "aiTitleCustomUserPrompt": "Custom User Prompt",
    "aiTitleMaxTokens": "Max Tokens",
    "aiTitleTemperature": "Temperature",
    "aiTitleTopP": "Top P",
    "aiTitleTopK": "Top K",
    "aiTitlePresencePenalty": "Presence Penalty",
    "aiTitleFrequencyPenalty": "Frequency Penalty",
    "aiTitleStopWords": "Stop Words",
    "truncateHistory": "Chat History Truncate",
    "truncateHistoryDesc": "Exclude older messages in the chat history, preserve on x number of messages for chat context",
    "notWorkingInO1": "OpenAI o1-series models does not apply this setting",
    "localEmbeddingSuppDesc1": "Currently using local embedding model",
    "localEmbeddingSuppDesc2": ", provided by Transformer.js and Huggingface.",
    "localEmbeddingSuppDesc3": "If the model failed to pull from Huggingface, recommended to use other embedding model provided by OpenAI or Ollama.",
    "providerEmbeddingSuppDesc1": "Currently using embedding model",
    "providerEmbeddingSuppDesc2": ", provided by ",
    "providerEmbeddingSuppDesc3": "For Ollama, ensure it is up and running when you are creating embeddings.",
    "aliasForMore": "@ more action",
    "matching": "match",
    "style": "style",
    "size": "size",
    "imageFnSupport1": "This function supported for OpenAI Dall-E 3 model only.",
    "searchForNbOrDoc": "Search for notebook or document",
    "intro1": "Hi, I'm your notebook assistant.",
    "intro2": "How can I help you today?",
    "gettingStarted": "Getting started",
    "model": "model",
    "removeMessage": "Are you sure you want to remove this message?",
    "yes": "Yes",
    "no": "No",
    "thoughtProcess": "Thought Process",
    "chatHistory": "Saved Chat",
    "gettingStarted1": "These buttons help you navigate between different views: Search, Vector Database, New Chat, History, and Chat.",
    "gettingStarted2": "Choose which AI model to use for your conversations.",
    "gettingStarted3": "Use @ commands for quick actions like saving chats, summarizing documents, auto-tagging, and adding context.",
    "gettingStarted4": "Type your messages here. Press Enter to send (can be configured in settings).",
    "gettingStarted5": "Configure your preferences, API keys, and other options.",
    "gettingStartedTitle1": "Navigation",
    "gettingStartedTitle2": "AI Model Selection",
    "gettingStartedTitle3": "Quick Actions",
    "gettingStartedTitle4": "Chat Input",
    "gettingStartedTitle5": "Settings",
    "nbNameOrDocName": "Notebook name / Document name",
    "imageGenDesc": "Describe the image you want to generate...",
    "summarizeDoc": "Summarize Doc",
    "addContext": "Add Context",
    "imageGeneration": "Image Generation",
    "vivid": "vivid",
    "natural": "natural",
    "documentName": "Document Name",
    "noteSaved": "Chat saved to note",
    "quckAct1": "Quick Action: Generating index for search"
}
